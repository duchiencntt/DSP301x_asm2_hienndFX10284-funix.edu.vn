{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastname_firstname_grade_the_exams.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYYLluqaZaH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import sys as sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKjj9mWXxwNT"
      },
      "source": [
        "'''\n",
        "@description Read a file\n",
        "@param {string} file_path - The path of the file\n",
        "@param {string} file_name - The name of the file\n",
        "@param {string} file_ext - The extension of the file\n",
        "@returns {DataFrame} - Vaild list\n",
        "'''\n",
        "def ReadFile(file_path, file_name, file_ext):\n",
        "  score_df = pd.DataFrame()\n",
        "  try:\n",
        "    with open(file_path + file_name + file_ext,'r') as file:\n",
        "      print('Successfully opened ' + file_name + file_ext + '\\n')\n",
        "      lines = file.readlines() \n",
        "\n",
        "#TODO: add invalid line to invalid list\n",
        "\n",
        "      invalid_list = []\n",
        "      for line in lines:\n",
        "        if len(line.replace('\\n','').split(',')) != 26 or line[0] != 'N' or not line[1:9].isdigit():\n",
        "          invalid_list.append(lines.index(line))\n",
        "\n",
        "      print('**** ANALYZING ****\\n')\n",
        "\n",
        "#TODO: print invalid list\n",
        "\n",
        "      if len(invalid_list) == 0:\n",
        "        print('No errors found!')\n",
        "      else:\n",
        "        for i in invalid_list:\n",
        "          line = lines[i]\n",
        "          if len(line.replace('\\n','').split(',')) != 26:\n",
        "            print('Invalid line of data: does not contain exactly 26 values:')\n",
        "          elif line[0] != 'N' or not line[1:9].isdigit():\n",
        "            print('Invalid line of data: N# is invalid')\n",
        "          else:\n",
        "            print('Invalid line of data: ')\n",
        "          print(line)\n",
        "        \n",
        "      print('\\n**** REPORT **** \\n')\n",
        "\n",
        "      print('Total valid lines of data: {}'.format(len(lines) - len(invalid_list)))\n",
        "      print('Total invalid lines of data: {}\\n'.format(len(invalid_list)))\n",
        "\n",
        " #TODO: read valid line by pandas read_csv     \n",
        " \n",
        "      score_df = pd.read_csv(file_path + file_name + file_ext, header=None, skiprows = invalid_list).fillna('')\n",
        "  except IOError:\n",
        "    print('File cannot be found.')\n",
        "  return score_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVcp_Iaux4Br"
      },
      "source": [
        "'''\n",
        "@description Do Mark\n",
        "@param {DataFrame} score_df - Student answer list\n",
        "@param {List} answer_key - Answer key list\n",
        "@returns {DataFrame} - Student grades list\n",
        "'''\n",
        "def DoMark(score_df, answer_key):\n",
        "  i = 0\n",
        "  for column in score_df.columns:\n",
        "    if i > 0:\n",
        "\n",
        "#TODO: mapping answer key\n",
        "\n",
        "      score_df[column] = score_df[column].map(lambda x: 4 if x == answer_key[i - 1] else x)\n",
        "      score_df[column] = score_df[column].map(lambda x: 0 if x == '' else x)\n",
        "      score_df[column] = score_df[column].map(lambda x: -1 if (x != 4 and x != 0) else x)\n",
        "    i += 1\n",
        "  score_df['Mark'] = score_df.sum(axis=1)\n",
        "\n",
        "#TODO: print report\n",
        "\n",
        "  print('Mean (average) score: {:.2f}'.format(score_df['Mark'].mean()))\n",
        "  print('Highest score: {}'.format(score_df['Mark'].max()))\n",
        "  print('Lowest score: {}'.format(score_df['Mark'].min()))\n",
        "  print('Range of scores: {}'.format(score_df['Mark'].max() - score_df['Mark'].min()))\n",
        "  print('Median score: {}'.format(score_df['Mark'].median()))\n",
        "  return score_df\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh8NtaOPg1-t"
      },
      "source": [
        "'''\n",
        "@description Write to file \n",
        "@param {string} file_path - The path of the file\n",
        "@param {string} file_name - The name of the file\n",
        "@param {string} file_ext - The extension of the file\n",
        "@param {DataFrame} score_df - Student grades list\n",
        "'''\n",
        "def WriteFile(file_path, file_name, file_ext, score_df):\n",
        "  score_df.to_csv(file_path + file_name + file_ext, columns=[0,'Mark'], header=False, index=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXbL_VOq5_rw"
      },
      "source": [
        "def MainTestGradeCalculator():\n",
        "#NOTE: Config Expected Output Path at here \n",
        "  expect_path = '/content/Data Files/Expected Output/'\n",
        "\n",
        "  #orig_stdout = sys.stdout\n",
        "  #sys.stdout = open(expect_path + 'expectedoutput.txt', 'a')\n",
        "\n",
        "  txt_input = 'Enter a class to grade (i.e. class1 for class1.txt): '\n",
        "  file_name = input(txt_input)\n",
        "  #print(txt_input + file_name)\n",
        "\n",
        "#NOTE: Config Data Files Path at here \n",
        "  file_path = '/content/Data Files/'\n",
        "  file_ext = '.txt'\n",
        "\n",
        "  answer_key = 'B,A,D,D,C,B,D,A,C,C,D,B,A,B,A,C,B,D,A,C,A,A,B,D,D'\n",
        "  answer_key = answer_key.split(',')\n",
        "\n",
        "#TODO: Begin Test Grade Calculator\n",
        "  score_df = ReadFile(file_path, file_name, file_ext)\n",
        "  if len(score_df) != 0:\n",
        "    score_df = DoMark(score_df, answer_key)\n",
        "    WriteFile(expect_path, file_name + '_grades', file_ext, score_df)\n",
        "\n",
        "  print('\\n\\n>>> ================================ RESTART ================================>>>')\n",
        "\n",
        "  #sys.stdout.close()\n",
        "  #sys.stdout = orig_stdout \n",
        "  #print('\\nThe path of the report is: ' + expect_path + 'expectedoutput.txt')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_4vr35FFxXW",
        "outputId": "c042d469-9ac6-4036-942b-ff1d0d657bb8"
      },
      "source": [
        "MainTestGradeCalculator()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a class to grade (i.e. class1 for class1.txt): class1\n",
            "Successfully opened class1.txt\n",
            "\n",
            "**** ANALYZING ****\n",
            "\n",
            "No errors found!\n",
            "\n",
            "**** REPORT **** \n",
            "\n",
            "Total valid lines of data: 20\n",
            "Total invalid lines of data: 0\n",
            "\n",
            "Mean (average) score: 75.60\n",
            "Highest score: 91\n",
            "Lowest score: 59\n",
            "Range of scores: 32\n",
            "Median score: 73.0\n",
            "\n",
            "\n",
            ">>> ================================ RESTART ================================>>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMg7zqZOFscV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}